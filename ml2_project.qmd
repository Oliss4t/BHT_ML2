---
title: "ML2 project"
editor: visual
---

## Load libraries

```{r message=FALSE}
library(dlookr)
library(corrplot)
library("PerformanceAnalytics")
library(splitTools)
library(ranger)
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
```

## Load data

```{r}
df.insurance <- read.csv(file ='./datasets/insurance.csv', header = TRUE)
describe(df.insurance)
```

## Reorganize data

```{r}
num.cols <- unlist(lapply(data, is.numeric))
num.cols <- c('age', 'bmi', 'children', 'charges')
cat.cols <- c('sex', 'smoker', 'region')
df.insurance <- df.insurance %>%
  mutate(sex = factor(sex, levels = unique(df.insurance$sex))) %>%
  mutate(smoker = factor(smoker, levels = unique(df.insurance$smoker))) %>%
  mutate(region = factor(region, levels = unique(df.insurance$region)))
```

## Plots correlation netween numerical features

```{r}
chart.Correlation(df.insurance[num.cols], histogram = TRUE, pch = 19)
```

## Plots correlation netween numerical features

```{r}
ggplot(df.insurance, aes(x = age, y = charges, fill = smoker, size = bmi, alpha = .3)) +
  geom_point(pch = 21) +
  scale_size_continuous(range = c(0, 10))

#eda_report(df.insurance, charges, output_format = "html", output_file = "EDA_insurance.html")

```

## Split dataset into 60% train set, 20% validation and 20% test set

```{r}

set.seed(1)
inds <- partition(df.insurance$charges, p = c(train = 0.6, valid = 0.2, test = 0.2))
str(inds)

#$ train: int [1:804] 2 3 7 8 9 11 12 15 16 18 ...
#$ valid: int [1:266] 5 17 19 31 36 41 46 47 49 51 ...
#$ test : int [1:268] 1 4 6 10 13 14 20 22 24 26 ...

train <- df.insurance[inds$train, ]
valid <- df.insurance[inds$valid, ]
test <- df.insurance[inds$test, ]

```

## Create simple linear model with 'charges' as outcome variable and inclusing all other columns as predictor variables.

```{r}

lm1 <- lm(charges ~ ., train)
summary(lm1)

```

## Predict the outcome of the validation set and calculate RMSE and R2 scores.

```{r}
lm1.pred <- predict(lm1, valid, se.fit = TRUE)
RMSE(lm1.pred$fit, valid$charges) # [1] 5914.46
R2(lm1.pred$fit, valid$charges) # [1] 0.7619868
```

## Predict the outcome of the test set and calculate RMSE and R2 scores.

```{r}
lm1.pred <- predict(lm1, test, se.fit = TRUE)
RMSE(lm1.pred$fit, test$charges)
# [1] 5670.218
R2(lm1.pred$fit, test$charges)
# 0.773166
```

## Create a Regression Tree and compare it to the baseline model

```{r, echo=FALSE}
tree.data<-rpart(charges~.,train)
print(tree.data)
```

Here we will follow the tactic of creating a full tree (i.e. totally overfitted) which will then be pruned back. We can see in the below plot how the error decreases as the complexity parameter decreases. Based on this plot a suitable complexity parameter is selected, and this quite interpretable decision tree is shown. 

```{r, echo=FALSE}

tree.data.full<-rpart(charges~.,train,cp=0)

cpmatrix<-printcp(tree.data.full)
plotcp(tree.data.full)

prune.data=prune(tree.data,cp=0.019)
rpart.plot(prune.data)
```

Let us predict and get some metrics as was done for the baseline model. Do this for the validation set. This is initially done on the full, overfitted tree, then on the default one, and then on the one with the selected complexity parameter
```{r}
pred.train.full <- predict(tree.data.full, valid, se.fit = TRUE)
RMSE(pred.train.full, valid$charges) 
R2(pred.train.full, valid$charges) 
```
and the test set
```{r}
pred.train.full <- predict(tree.data.full, test, se.fit = TRUE)
RMSE(pred.train.full, test$charges) 
R2(pred.train.full, test$charges) 
```

Repeat for the other two models
Default:
```{r}
pred.train.default <- predict(tree.data, valid, se.fit = TRUE)
RMSE(pred.train.default, valid$charges) 
R2(pred.train.default, valid$charges) 
```
```{r}
pred.train.default <- predict(tree.data, test, se.fit = TRUE)
RMSE(pred.train.default, test$charges) 
R2(pred.train.default, test$charges) 
```

Pruned:
```{r}
pred.train.pruned <- predict(prune.data, valid, se.fit = TRUE)
RMSE(pred.train.pruned, valid$charges) 
R2(pred.train.pruned, valid$charges) 
```
```{r}
pred.train.pruned <- predict(prune.data, test, se.fit = TRUE)
RMSE(pred.train.pruned, test$charges) 
R2(pred.train.pruned, test$charges) 
```

## Hyperparamter optimisation

Finding the optimal complexity parameter via grid search:

```{r}
param_grid <- expand.grid(cp = seq(0.01, 0.5, 0.01))

regtree <- train(
  charges ~ .,
  data = train,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = param_grid
)

print(regtree$bestTune)

predictions <- predict(regtree, newdata = test)

RMSE(predictions, test$charges) 
R2(predictions, test$charges) 
```


